# Role of Tweaks in Deep Learning

This repo contains our project "Role of Tweaks in Deep Learning" as a part of the course "Generalisation properties of Machine Learning" - Professor Aymeric Dieuleveut (Ecole Polytechnique).

This project aims to study the roles of Deep Learning generalisation techniques (or "tweaks") such as Dropout, Batch Normalization, Weight Initialization or Weight Decay. We evaluate these techniques on the CIFAR-10 Image Classification task with Convolutional Neural Networks (CNNs) architectures.